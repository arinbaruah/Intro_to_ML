---
title: "ETC3250/5250 Assignment 1"
author: "Arindom Baruah (32779267)"
date: "2024-03-22"
quarto-required: ">=1.3.0"
format:
    html:
        output-file: assign01-submission.html
        css: "assignment.css"
execute: 
  echo: false
  message: false
  warning: false
---

```{r}

draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)


  rect(150, 430, 240, 370, col='#67A069')
  text(195, 435, 'Bilby', cex=1.2)
  rect(250, 430, 340, 370, col='#CB6E4F')
  text(295, 435, 'Quokka', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#CB6E4F')
  rect(250, 305, 340, 365, col='#67A069')
  text(140, 400, 'Bilby', cex=1.2, srt=90)
  text(140, 335, 'Quokka', cex=1.2, srt=90)


  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')


  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "MODEL PERFORMANCE METRICS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[8]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[8]), 3), cex=1.2)


  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$byClass[11]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$byClass[11]), 3), cex=1.4)
}  
```



```{r}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(kableExtra)
library(caret)
library(plotROC)
library(mulgar)
library(tourr)
library(GGally)
library(uwot)
library(animation)
library(magick)
```


# Exercises

## 1. Basic math and computing 


```{r echo=TRUE}

S <- rbind(c(3,1),c(1,2))
X <- rbind(4,2)
A <- rbind(1,-1)


Matrix_calculation <- t(X-A) %*% solve(S) %*% (X-A)

```
The matrix calculation for computing $(X-A)^T S^{-1}(X-A)$ yields the result __`r Matrix_calculation[1,1]`__.


## 2. ML concepts

### a) Model accuracy



```{r}
#| label: tbl-data
#| tbl-cap: "Sample rows of the current data"
d_pred <- read_csv("https://raw.githubusercontent.com/numbats/iml/master/data/pred_data.csv")
d_pred |> slice_head(n=3) %>% kbl()
```
The computations to assess the model metrics are delineated in the panel tabsets below.

:::panel-tabset

#### Model 1 

```{r}
model_1 <- d_pred %>% dplyr::select(c("y","pred1","bilby1","quokka1"))

model_1$y <- as.factor(model_1$y)
model_1$pred1 <- as.factor(model_1$pred1)
model_2 <- d_pred %>% dplyr::select(c("y","pred2","bilby2","quokka2"))
model_2$y <- as.factor(model_2$y)
model_2$pred2 <- as.factor(model_2$pred2)
```

```{r}
cm_1 <- model_1 %>% count(y,pred1) %>% group_by(y) %>%
  mutate(cl_acc = n[pred1==y]/sum(n)) %>% pivot_wider(names_from = pred1,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)
```

The accuracy for `model 1` which is calculated based on the number of true positives and the true negatives is observed to be __`r accuracy(model_1,y,pred1) %>% pull(.estimate) %>% round(3)`__.

However, the accuracy parameter for a model may not always be the best indicator. This is especially true when the data may contain unbalanced class distribution. In this case, we will rely on balanced accuracy which is based on the true positive and the true negative rate of prediction for the model.

The balanced accuracy for `model 1` is found to be __`r bal_accuracy(model_1,y,pred1) %>% pull(.estimate) %>% round(3)`__.

@fig-confmat1 illustrates the detailed confusion matrix for `model 1` with the critical model parameters which are useful indicators of model performance.

```{r}
#| label: fig-confmat1
#| fig-cap: "Confusion matrix with key performance metrics of model 1"
model_1_cm <- confusionMatrix(model_1$pred1,model_1$y)

draw_confusion_matrix(model_1_cm)
```

#### Model 2 



```{r}
cm_2 <- model_2 %>% count(y,pred2) %>% group_by(y) %>%
  mutate(cl_acc = n[pred2==y]/sum(n)) %>% pivot_wider(names_from = pred2,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)
```

The accuracy for `model 2` which is calculated based on the number of true positives and the true negatives is observed to be __`r accuracy(model_2,y,pred2) %>% pull(.estimate) %>% round(3)`__. The balanced accuracy for the same model which is based on the true positive and the true negative rates are  __`r bal_accuracy(model_2,y,pred2) %>% pull(.estimate) %>% round(3)`__.

@fig-confmat2 illustrates the detailed confusion matrix for `model 2`. 

```{r}
#| label: fig-confmat2
#| fig-cap: "Confusion matrix with key performance metrics of model 2"
model_2_cm <- confusionMatrix(model_2$pred2,model_2$y)

draw_confusion_matrix(model_2_cm)
```

:::{.callout-note}
# Key takeaway

As we can observe from the model metrics in @fig-confmat1 and @fig-confmat2, the model 1 was observed to classify the labelled data more accurately than model 2.
:::

:::

### b) Sensitivity and Specificity with revised threshold values


:::panel-tabset

### Classification threshold of 0.3

#### 1) When the threshold value for classification in model 1 is 0.3

```{r}
model_new_1a <- model_1
model_new_1a <- model_new_1a %>% mutate(pred1 = if_else(bilby1 >= 0.3,"bilby","quokka")) 
model_new_1a$y <- as.factor(model_new_1a$y)
model_new_1a$pred1 <- as.factor(model_new_1a$pred1)



cm_new_1a <- model_new_1a %>% count(y,pred1) %>% group_by(y) %>%
  mutate(cl_acc = n[pred1==y]/sum(n)) %>% pivot_wider(names_from = pred1,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```

The sensitivity for `model 1` when the threshold value for positive Bilby classification is 0.3 and above is __`r sens(model_new_1a,y,pred1) %>% pull(.estimate) %>% round(3)`__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __`r 1-spec(model_new_1a,y,pred1) %>% pull(.estimate) %>% round(3)`__.



```{r}
#| label: fig-confmat_new_1a
#| fig-cap: "Confusion matrix with key performance metrics of model 1 when considering 0.3 as the threshold value for positive Bilby classification"
model_new_1a_cm <- confusionMatrix(model_new_1a$pred1,model_new_1a$y)

draw_confusion_matrix(model_new_1a_cm)

```
#### 2) When the threshold value for classification in model 2 is 0.3

```{r}
model_new_2a <- model_2
model_new_2a <- model_new_2a %>% mutate(pred2 = if_else(bilby2 >= 0.3,"bilby","quokka")) 
model_new_2a$y <- as.factor(model_new_2a$y)
model_new_2a$pred2 <- as.factor(model_new_2a$pred2)



model_new_2a_cm <- model_new_2a %>% count(y,pred2) %>% group_by(y) %>%
  mutate(cl_acc = n[pred2==y]/sum(n)) %>% pivot_wider(names_from = pred2,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```

```{r}
#| label: fig-confmat_new_2a
#| fig-cap: "Confusion matrix with key performance metrics of model 2 when considering 0.3 as the threshold value for positive Bilby classification"
model_new_2a_cm <- confusionMatrix(model_new_2a$pred2,model_new_2a$y)

draw_confusion_matrix(model_new_2a_cm)

```
The sensitivity for `model 2` when the threshold value for positive Bilby classification is 0.3 and above is __`r sens(model_new_2a,y,pred2) %>% pull(.estimate) %>% round(3)`__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __`r 1-spec(model_new_2a,y,pred2) %>% pull(.estimate) %>% round(3)`__. Other detailed model performance metrics for model 2 with a threshold value of 0.3 can be referred to in @fig-confmat_new_2a.

### Classification threshold of 0.4

#### 1) When the threshold value for classification in model 1 is 0.4

```{r}
model_new_1b <- model_1
model_new_1b <- model_new_1b %>% mutate(pred1 = if_else(bilby1 >= 0.4,"bilby","quokka")) 
model_new_1b$y <- as.factor(model_new_1b$y)
model_new_1b$pred1 <- as.factor(model_new_1b$pred1)



cm_new_1b <- model_new_1b %>% count(y,pred1) %>% group_by(y) %>%
  mutate(cl_acc = n[pred1==y]/sum(n)) %>% pivot_wider(names_from = pred1,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```

```{r}
#| label: fig-confmat_new_1b
#| fig-cap: "Confusion matrix with key performance metrics of model 1 when considering 0.4 as the threshold value for positive Bilby classification"
model_new_1b_cm <- confusionMatrix(model_new_1b$pred1,model_new_1b$y)

draw_confusion_matrix(model_new_1b_cm)

```




#### 2) When the threshold value for classification in model 2 is 0.4

```{r}
model_new_2b <- model_2
model_new_2b <- model_new_2b %>% mutate(pred2 = if_else(bilby2 >= 0.4,"bilby","quokka")) 
model_new_2b$y <- as.factor(model_new_2b$y)
model_new_2b$pred2 <- as.factor(model_new_2b$pred2)



model_new_2b_cm <- model_new_2b %>% count(y,pred2) %>% group_by(y) %>%
  mutate(cl_acc = n[pred2==y]/sum(n)) %>% pivot_wider(names_from = pred2,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```




```{r}
#| label: fig-confmat_new_2b
#| fig-cap: "Confusion matrix with key performance metrics of model 2 when considering 0.4 as the threshold value for positive Bilby classification"
model_new_2b_cm <- confusionMatrix(model_new_2b$pred2,model_new_2b$y)

draw_confusion_matrix(model_new_2b_cm)

```

The sensitivity for `model 2` when the threshold value for positive Bilby classification is 0.4 and above is __`r sens(model_new_2b,y,pred2) %>% pull(.estimate) %>% round(3)`__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __`r 1-spec(model_new_2b,y,pred2) %>% pull(.estimate) %>% round(3)`__. Other detailed model performance metrics for model 2 with a threshold value of 0.3 can be referred to in @fig-confmat_new_2b.

:::

### c) Receiver Operative Curve (ROC) visualisation for model output

```{r }
#| label: fig-roc
#| fig-cap: "Receiver Operative Curve visualisation for comparison of model performance based on Sensitivty and 1-Specificity"

roc_curve_1 <- roc_curve(model_new_1b,y,bilby1) 
roc_curve_2 <- roc_curve(model_new_2a,y,bilby2)

pl1 <- ggplot() +
  geom_path(data = roc_curve_1, aes(x = 1 - specificity, y = sensitivity, color = "Model 1"),size = 1.5) + 
  geom_path(data = roc_curve_2, aes(x = 1 - specificity, y = sensitivity, color = "Model 2"),size = 1.5) + 
  geom_abline(slope = 1,linetype = 2,alpha = 0.5) +
  scale_color_manual(values = c("Model 1" = "blue", "Model 2" = "red")) +
  ggtitle("Receiver Operating Curve for model comparison") + labs(colour = "Model type") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5))
pl1

```

:::{.callout-note}
# Key takeaway

As we can observe from @fig-roc, the area under the curve (AUC) covered by the ROC of __model 1 is larger when in comparison to model 2__. This indicates that the __model 1 is performing better than the results obtained through model 2__.

The higher the curve is to the top left point of the plot, the higher the true positive rate of the model (measured through sensitivity) as well as the least false positive rate (measured through 1-specificity).
:::

## 3. Visualisation 

Here, we are required to visualise a high-dimensional data which contains 6 different variables. Due to the complexity of the data in hand and the multiple dimensions we are looking to study, it is often not possible to understand the correlation of each dimension through simple 2-dimensional plots such as scatter plots. Hence, we will be primarily studying the data through various high dimensional visualisation techniques, namely scatter plot matrix, UMAP and the grand tour.

### a) 2D Scatter plot matrix

```{r}
#| label: fig-scatmat
#| fig-cap: "2D scatter plot matrix"
ggscatmat(c7)
```
:::{.callout-note}
# Key takeaway

Based on the scatter plot matrix as illustrated by @fig-scatmat, it is __difficult to ascertain any particular pattern__ when evaluating each of the pair of variables against one another. While there appears to be a very weak relationship between X1 and X2 owing to a correlation of 0.45, however, it is difficult to obtain any insight as the scatter points are randomly spread out on the 2D space. The remaining pair of variables show even weaker correlation, __thereby indicating that each of the pair of variables are non-linearly related to one another.__
:::

### b) Non-linear dimension reduction using UMAP

The uniform manifold approximation and projection (UMAP) compares the interpoint distances with what might be expected if the data was uniformly distributed in the high dimensional shapes.
```{r}
#| label: fig-umap
#| fig-cap: "UMAP representation of the data"

set.seed(253)
c7_tidy_umap <- umap(c7, init = "spca")

c7_tidy_umap_df <- c7_tidy_umap |>
  as_tibble() |>
  rename(UMAP1 = V1, UMAP2 = V2) 
ggplot(c7_tidy_umap_df, aes(x = UMAP1, 
                           y = UMAP2)) +
  geom_point(colour = "#EC5C00") 
```

:::{.callout-note}

Based on the UMAP representation of the data on a 2D space upon reducing the dimensions into UMAP1 and UMAP2, we can observe that the data points have segregated into two regions of the plane, thereby creating __two clusters__. On the bottom left of the 2D space, we can clearly recognise the cluster due to most points concentrating close to one another. However, for the remaining set of the data, there is a high variance and these points cover a wide space on the 2D plane. While some of those points appear to be concentrating in the center (possibly due to clumping), however, the remaining points are much more widely spread.

Hence, we can expect __a fair number of outliers__ while visualising the second cluster.
:::

### c) High-dimensional data visualisation using the grand tour

While we have already visualised the data on the 2D space by looking at the correlation among the variables, we now attempt to visualise the high-dimensional data in its true form by creating a tour which is an animation of the data points in the multi-dimensional space. The main advantage of this technique is that there is no information lost when drawing insights as we are effectively looking at all the data points in its original dimensions.



```{r eval=FALSE}
gif_file <- "animated_xy.gif"
ani.options(interval = 0.1, ani.width = 500, ani.height = 400)

saveGIF({
  animate_xy(c7)
}, movie.name = gif_file, interval = 0.1, ani.width = 500, ani.height = 400)

```

```{r}
#| label: fig-c7gif
#| fig-cap: "High-dimesional tour for the C7 dataset"
image <- image_read("animated_xy.gif")
image_animate(image)
```

:::{.callout-note}
# Key takeaway

- While analysing the tour as illustrated by @fig-c7gif, we can observe the presence of a particular cluster of points which are concentrated close to one another. This was previously detected in @fig-umap aswell.

- In addition to the above finding, we can also observe that the points other than those in the identified cluster appear to be entirely on the plane generated by the axes X1 and X2.This information was not possible to obtain from @fig-umap due to its inherent functionality of reducing all the dimensions to two dimensions, thereby reducing the interpretability of the plot.

- There also appears to be a particular orientation of the dimensions when the scatter points __are linearly arranged__. This was observed __through a combination of the dimensions X3,X5 and X6__.


:::








#### 4. Dimension reduction (15pts)

YOUR ANSWER HERE

## References

Hadley Wickham, Dianne Cook, Heike Hofmann, Andreas Buja
  (2011). tourr: An R Package for Exploring Multivariate
  Data with Projections. Journal of Statistical Software,
  40(2), 1-18. URL http://www.jstatsoft.org/v40/i02/.
  
Kuhn et al., (2020). Tidymodels: a collection of
  packages for modeling and machine learning using
  tidyverse principles. https://www.tidymodels.org  
  
OpenAI (2023). ChatGPT (version 3.5) [Large language model]. https://chat.openai.com/chat, full script of conversation [here]( https://chat.openai.com/share/746c4f77-9b7b-4c3b-867a-826f639b91aa)