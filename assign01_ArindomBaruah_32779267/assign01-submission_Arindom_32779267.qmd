---
title: "ETC3250/5250 Assignment 1"
author: "Arindom Baruah (32779267)"
date: "2024-03-22"
quarto-required: ">=1.3.0"
format:
    html:
        output-file: assign01-submission.html
        css: "assignment.css"
execute: 
  echo: false
  message: false
  warning: false
---

```{r}

draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)


  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'Bilby', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'Quokka', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'Bilby', cex=1.2, srt=90)
  text(140, 335, 'Quokka', cex=1.2, srt=90)


  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')


  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[8]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[8]), 3), cex=1.2)


  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$byClass[11]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$byClass[11]), 3), cex=1.4)
}  
```



```{r}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(kableExtra)
library(caret)
library(plotROC)
```


# Exercises

## 1. Basic math and computing 


```{r echo=TRUE}

S <- rbind(c(3,1),c(1,2))
X <- rbind(4,2)
A <- rbind(1,-1)


Matrix_calculation <- t(X-A) %*% solve(S) %*% (X-A)

```
The matrix calculation for computing $(X-A)^T S^{-1}(X-A)$ yields the result __`r Matrix_calculation[1,1]`__.


## 2. ML concepts

### a) Model accuracy



```{r}
#| label: tbl-data
#| tbl-cap: "Sample rows of the current data"
d_pred <- read_csv("https://raw.githubusercontent.com/numbats/iml/master/data/pred_data.csv")
d_pred |> slice_head(n=3) %>% kbl()
```

#### Model 1 

```{r}
model_1 <- d_pred %>% dplyr::select(c("y","pred1","bilby1","quokka1"))

model_1$y <- as.factor(model_1$y)
model_1$pred1 <- as.factor(model_1$pred1)
model_2 <- d_pred %>% dplyr::select(c("y","pred2","bilby2","quokka2"))
model_2$y <- as.factor(model_2$y)
model_2$pred2 <- as.factor(model_2$pred2)
```

```{r}
cm_1 <- model_1 %>% count(y,pred1) %>% group_by(y) %>%
  mutate(cl_acc = n[pred1==y]/sum(n)) %>% pivot_wider(names_from = pred1,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)
```

The accuracy for `model 1` which is calculated based on the number of true positives and the true negatives is observed to be __`r accuracy(model_1,y,pred1) %>% pull(.estimate) %>% round(3)`__.

However, the accuracy parameter for a model may not always be the best indicator. This is especially true when the data may contain unbalanced class distribution. In this case, we will rely on balanced accuracy which is based on the true positive and the true negative rate of prediction for the model.

The balanced accuracy for `model 1` is found to be __`r bal_accuracy(model_1,y,pred1) %>% pull(.estimate) %>% round(3)`__.

@fig-confmat1 illustrates the detailed confusion matrix for `model 1` with the critical model parameters which are useful indicators of model performance.

```{r}
#| label: fig-confmat1
#| fig-cap: "Confusion matrix with key performance metrics of model 1"
model_1_cm <- confusionMatrix(model_1$pred1,model_1$y)

draw_confusion_matrix(model_1_cm)
```

#### Model 2 



```{r}
cm_2 <- model_2 %>% count(y,pred2) %>% group_by(y) %>%
  mutate(cl_acc = n[pred2==y]/sum(n)) %>% pivot_wider(names_from = pred2,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)
```

The accuracy for `model 2` which is calculated based on the number of true positives and the true negatives is observed to be __`r accuracy(model_2,y,pred2) %>% pull(.estimate) %>% round(3)`__. The balanced accuracy for the same model which is based on the true positive and the true negative rates are  __`r bal_accuracy(model_2,y,pred2) %>% pull(.estimate) %>% round(3)`__.

@fig-confmat2 illustrates the detailed confusion matrix for `model 2`. 

```{r}
#| label: fig-confmat2
#| fig-cap: "Confusion matrix with key performance metrics of model 2"
model_2_cm <- confusionMatrix(model_2$pred2,model_2$y)

draw_confusion_matrix(model_2_cm)
```

:::{.callout-note}
# Key takeaway

As we can observe from the model metrics in @fig-confmat1 and @fig-confmat2, the model 1 was observed to classify the labelled data more accurately than model 2.
:::

### b) Sensitivity and Specificity with revised threshold values

#### 1) When the threshold value for classification in model 1 is 0.3

```{r}
model_new_1a <- model_1
model_new_1a <- model_new_1a %>% mutate(pred1 = if_else(bilby1 >= 0.3,"bilby","quokka")) 
model_new_1a$y <- as.factor(model_new_1a$y)
model_new_1a$pred1 <- as.factor(model_new_1a$pred1)



cm_new_1a <- model_new_1a %>% count(y,pred1) %>% group_by(y) %>%
  mutate(cl_acc = n[pred1==y]/sum(n)) %>% pivot_wider(names_from = pred1,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```

The sensitivity for `model 1` when the threshold value for positive Bilby classification is 0.3 and above is __`r sens(model_new_1a,y,pred1) %>% pull(.estimate) %>% round(3)`__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __`r 1-spec(model_new_1a,y,pred1) %>% pull(.estimate) %>% round(3)`__.



```{r}
#| label: fig-confmat_new_1a
#| fig-cap: "Confusion matrix with key performance metrics of model 1 when considering 0.3 as the threshold value for positive Bilby classification"
model_new_1a_cm <- confusionMatrix(model_new_1a$pred1,model_new_1a$y)

draw_confusion_matrix(model_new_1a_cm)

```
#### 2) When the threshold value for classification in model 1 is 0.4

```{r}
model_new_1b <- model_1
model_new_1b <- model_new_1b %>% mutate(pred1 = if_else(bilby1 >= 0.4,"bilby","quokka")) 
model_new_1b$y <- as.factor(model_new_1b$y)
model_new_1b$pred1 <- as.factor(model_new_1b$pred1)



cm_new_1b <- model_new_1b %>% count(y,pred1) %>% group_by(y) %>%
  mutate(cl_acc = n[pred1==y]/sum(n)) %>% pivot_wider(names_from = pred1,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```

```{r}
#| label: fig-confmat_new_1b
#| fig-cap: "Confusion matrix with key performance metrics of model 1 when considering 0.4 as the threshold value for positive Bilby classification"
model_new_1b_cm <- confusionMatrix(model_new_1b$pred1,model_new_1b$y)

draw_confusion_matrix(model_new_1b_cm)

```

#### 3) When the threshold value for classification in model 2 is 0.3

```{r}
model_new_2a <- model_2
model_new_2a <- model_new_2a %>% mutate(pred2 = if_else(bilby2 >= 0.3,"bilby","quokka")) 
model_new_2a$y <- as.factor(model_new_2a$y)
model_new_2a$pred2 <- as.factor(model_new_2a$pred2)



model_new_2a_cm <- model_new_2a %>% count(y,pred2) %>% group_by(y) %>%
  mutate(cl_acc = n[pred2==y]/sum(n)) %>% pivot_wider(names_from = pred2,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```

The sensitivity for `model 2` when the threshold value for positive Bilby classification is 0.3 and above is __`r sens(model_new_2a,y,pred2) %>% pull(.estimate) %>% round(3)`__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __`r 1-spec(model_new_2a,y,pred2) %>% pull(.estimate) %>% round(3)`__. Other detailed model performance metrics for model 2 with a threshold value of 0.3 can be referred to in @fig-confmat_new_2a.



```{r}
#| label: fig-confmat_new_2a
#| fig-cap: "Confusion matrix with key performance metrics of model 2 when considering 0.3 as the threshold value for positive Bilby classification"
model_new_2a_cm <- confusionMatrix(model_new_2a$pred2,model_new_2a$y)

draw_confusion_matrix(model_new_2a_cm)

```

#### 4) When the threshold value for classification in model 2 is 0.4

```{r}
model_new_2b <- model_2
model_new_2b <- model_new_2b %>% mutate(pred2 = if_else(bilby2 >= 0.4,"bilby","quokka")) 
model_new_2b$y <- as.factor(model_new_2b$y)
model_new_2b$pred2 <- as.factor(model_new_2b$pred2)



model_new_2b_cm <- model_new_2b %>% count(y,pred2) %>% group_by(y) %>%
  mutate(cl_acc = n[pred2==y]/sum(n)) %>% pivot_wider(names_from = pred2,
                                                      values_from = n) %>%
  dplyr::select(y,bilby,quokka,cl_acc)


```




```{r}
#| label: fig-confmat_new_2b
#| fig-cap: "Confusion matrix with key performance metrics of model 2 when considering 0.4 as the threshold value for positive Bilby classification"
model_new_2b_cm <- confusionMatrix(model_new_2b$pred2,model_new_2b$y)

draw_confusion_matrix(model_new_2b_cm)

```

The sensitivity for `model 2` when the threshold value for positive Bilby classification is 0.4 and above is __`r sens(model_new_2b,y,pred2) %>% pull(.estimate) %>% round(3)`__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __`r 1-spec(model_new_2b,y,pred2) %>% pull(.estimate) %>% round(3)`__. Other detailed model performance metrics for model 2 with a threshold value of 0.3 can be referred to in @fig-confmat_new_2b.

### c) Receiver Operative Curve (ROC) visualisation for model output

```{r }
#| label: fig-roc
#| fig-cap: "Receiver Operative Curve visualisation for comparison of model performance based on Sensitivty and 1-Specificity"

roc_curve_1 <- roc_curve(model_new_1b,y,bilby1) 
roc_curve_2 <- roc_curve(model_new_2a,y,bilby2)

pl1 <- ggplot() +
  geom_path(data = roc_curve_1, aes(x = 1 - specificity, y = sensitivity, color = "Model 1"),size = 1.5) + 
  geom_path(data = roc_curve_2, aes(x = 1 - specificity, y = sensitivity, color = "Model 2"),size = 1.5) + 
  geom_abline(slope = 1,linetype = 2,alpha = 0.5) +
  scale_color_manual(values = c("Model 1" = "blue", "Model 2" = "red")) +
  ggtitle("Receiver Operating Curve for model comparison") + labs(colour = "Model type") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5))
pl1

```

```{r}
roc_curve(model_new_1b,y,bilby1) %>% autoplot()

```

#### 3. Visualisation (8pts)

YOUR ANSWER HERE

#### 4. Dimension reduction (15pts)

YOUR ANSWER HERE

## References

Hadley Wickham, Dianne Cook, Heike Hofmann, Andreas Buja
  (2011). tourr: An R Package for Exploring Multivariate
  Data with Projections. Journal of Statistical Software,
  40(2), 1-18. URL http://www.jstatsoft.org/v40/i02/.
  
Kuhn et al., (2020). Tidymodels: a collection of
  packages for modeling and machine learning using
  tidyverse principles. https://www.tidymodels.org  
  
OpenAI (2023). ChatGPT (version 3.5) [Large language model]. https://chat.openai.com/chat, full script of conversation [here]( https://chat.openai.com/share/746c4f77-9b7b-4c3b-867a-826f639b91aa)